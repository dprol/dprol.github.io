---
title: The Future of Software Development and the Role of Computing Education with LLMs
image: /assets/img/blog/iStock-1468187710.jpg
description: >
  Pic from iStock <!--more-->
---

Are you curious about the future of software development and how LLMs could reshape the way we train junior developers?

The InfoQ podcast has an <a href="https://www.infoq.com/podcasts/llms-programming-tasks-training-developers/">insightful conversation</a> with Anthony Alford, Senior Director of Development at Genesys, and Roland Meertens, an ML engineer building self-driving cars at Wayve, that you won't want to miss. Here's my summary of the episode.

<!--more-->

The rapid advancement of Large Language Models (LLMs) is poised to revolutionize the software development landscape. These powerful AI systems can automate a wide range of tasks, from writing code and generating tests to debugging and optimizing algorithms. While this automation promises increased productivity and efficiency, it also raises critical questions about the role of human developers and the future of computing education.

Proponents of LLMs envision a future where tedious and repetitive tasks, such as code reviews, documentation, and variable naming, are handled by these AI assistants, freeing up human engineers to focus on more complex problem-solving. Junior developers, who traditionally spent countless hours scouring online communities and debugging basic code, could now leverage LLMs as interactive learning tools, absorbing patterns and best practices through AI-generated examples and guidance.

However, this technological shift is not without its concerns. One pressing issue is the potential loss of contextual understanding among developers. As LLMs take over more tasks, there is a risk that developers may lose sight of the broader context, meta-problems, and the limitations of the tools they are using. This could lead to situations where developers blindly trust the AI's output without fully comprehending its implications or potential drawbacks.

Another concern revolves around code quality and maintainability. While LLMs can generate code, there are valid concerns about its elegance, readability, and potential for creating "spaghetti code" that is difficult to maintain and debug. This raises questions about how developers will understand and fix issues that arise in LLM-generated code, especially in critical systems like autonomous vehicles, where a single error could have catastrophic consequences.

As the software development industry grapples with these challenges, Anthony and Roland emphasize the importance of striking the right balance between automation and human oversight. While LLMs can undoubtedly increase productivity, developers must exercise restraint and not blindly accept every AI-generated suggestion. Instead, they should critically evaluate the output, considering its implications and potential drawbacks.

One proposed solution is to embrace rigorous testing frameworks and practices. By implementing comprehensive unit, scenario, and use case tests, developers can ensure the quality and reliability of LLM-generated code. Additionally, maintaining a core team of experienced developers who can debug and tweak the code as needed could provide a crucial safety net.

As LLMs become more prevalent in software development, the role of computing education will also evolve. Educational institutions and training programs will need to adapt their curricula to equip the next generation of developers with the skills and mindset necessary to work effectively alongside these AI assistants.

This may involve fostering critical thinking, problem-solving abilities, and a deep understanding of the underlying principles and best practices of software engineering. Developers will need to learn how to respect the technology's limitations, recognizing when human intervention is necessary and when it is safe to leverage the AI's capabilities.

Moreover, hands-on experience and the opportunity to make mistakes in a controlled environment will be crucial for aspiring developers. By allowing them to grapple with challenges and learn from their missteps, educators can instill a sense of caution and respect for the technology, ensuring that developers do not become overly reliant on LLMs or lose sight of the broader context.
